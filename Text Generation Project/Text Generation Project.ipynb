{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import numpy\n",
    "import sys\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file = open(\"C:/Users/prane/Desktop/Frankenstein-2.txt\", 'r', encoding = ('utf-8')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# Standardization\n",
    "def tokenize_words(input):\n",
    "    # Everything has been converted to lowercase for standardization\n",
    "    input = input.lower()\n",
    "    # Instantiating the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # Tokenizing the text into tokens\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    # Filtering out the stopwords using lambda\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return ' '.join(filtered)\n",
    "# Preprocessing the input data, making tokens\n",
    "processed_inputs = tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting characters to numbers\n",
    "# Converting our characters to numbers\n",
    "# Sorting the list of all of our characters that appear in our input text and then using the enumerate function to get numbers\n",
    "# that represent the characters\n",
    "# Next, creating a dictionary to store the keys and values, in this case the characters and the numbers that represent them\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters:  8086\n",
      "Total vocab:  28\n"
     ]
    }
   ],
   "source": [
    "# Checking if characters to numbers or vice versa has worked\n",
    "# printing the length of the variables\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print(\"Total number of characters: \", input_len)\n",
    "print(\"Total vocab: \", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length\n",
    "# Defining the length of our sequence\n",
    "# A sequence is a complete mapping of input characters as integers\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns:  7986\n"
     ]
    }
   ],
   "source": [
    "# Looping through the sequence\n",
    "# Going through the entire list of inputs and converting the characters to numbers using a for loop\n",
    "# This will create a bunch of sequences where each sequence starts with the next character in the input data beginning with \n",
    "# the first character\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    # Defining input and output sequences\n",
    "    # Input sequence is the current character plus the sequence length\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "    # Output sequence is the initial character plus the total sequence length\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "    # Converting the list of characters to integers based on previous values and then appnding them to the list\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "    \n",
    "# Checking to see how many input sequences we have    \n",
    "n_patterns = len(x_data)\n",
    "print(\"Total patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting input sequence to np array that the network can use\n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the label data\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "# Creating a sequential model\n",
    "# Dropout is used to prevent overfitting of our data\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2]), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the weights\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4356\n",
      "Epoch 00001: loss improved from 2.44904 to 2.43565, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 102s 2s/step - loss: 2.4356\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4029\n",
      "Epoch 00002: loss improved from 2.43565 to 2.40292, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 2.4029\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3856\n",
      "Epoch 00003: loss improved from 2.40292 to 2.38557, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 2.3856\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3605\n",
      "Epoch 00004: loss improved from 2.38557 to 2.36045, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.3605\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3481\n",
      "Epoch 00005: loss improved from 2.36045 to 2.34812, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.3481\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3179\n",
      "Epoch 00006: loss improved from 2.34812 to 2.31788, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 2.3179\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3100\n",
      "Epoch 00007: loss improved from 2.31788 to 2.31000, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.3100\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2766\n",
      "Epoch 00008: loss improved from 2.31000 to 2.27656, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.2766\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2603\n",
      "Epoch 00009: loss improved from 2.27656 to 2.26026, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.2603\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2424\n",
      "Epoch 00010: loss improved from 2.26026 to 2.24245, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 107s 2s/step - loss: 2.2424\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2142\n",
      "Epoch 00011: loss improved from 2.24245 to 2.21421, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.2142\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2072\n",
      "Epoch 00012: loss improved from 2.21421 to 2.20716, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 106s 2s/step - loss: 2.2072\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1735\n",
      "Epoch 00013: loss improved from 2.20716 to 2.17346, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.1735\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1513\n",
      "Epoch 00014: loss improved from 2.17346 to 2.15126, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.1513\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1267\n",
      "Epoch 00015: loss improved from 2.15126 to 2.12668, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.1267\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1030\n",
      "Epoch 00016: loss improved from 2.12668 to 2.10303, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 2.1030\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0783\n",
      "Epoch 00017: loss improved from 2.10303 to 2.07832, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.0783\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0591\n",
      "Epoch 00018: loss improved from 2.07832 to 2.05908, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.0591\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0421\n",
      "Epoch 00019: loss improved from 2.05908 to 2.04210, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.0421\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0094\n",
      "Epoch 00020: loss improved from 2.04210 to 2.00945, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 2.0094\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9934\n",
      "Epoch 00021: loss improved from 2.00945 to 1.99337, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.9934\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9457\n",
      "Epoch 00022: loss improved from 1.99337 to 1.94568, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.9457\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9161\n",
      "Epoch 00023: loss improved from 1.94568 to 1.91611, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 1.9161\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8944\n",
      "Epoch 00024: loss improved from 1.91611 to 1.89440, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.8944\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8614\n",
      "Epoch 00025: loss improved from 1.89440 to 1.86141, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 1.8614\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8265\n",
      "Epoch 00026: loss improved from 1.86141 to 1.82651, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.8265\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8094\n",
      "Epoch 00027: loss improved from 1.82651 to 1.80942, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.8094\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7835\n",
      "Epoch 00028: loss improved from 1.80942 to 1.78352, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.7835\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7599\n",
      "Epoch 00029: loss improved from 1.78352 to 1.75987, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 106s 2s/step - loss: 1.7599\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7292\n",
      "Epoch 00030: loss improved from 1.75987 to 1.72922, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.7292\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6970\n",
      "Epoch 00031: loss improved from 1.72922 to 1.69703, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.6970\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6650\n",
      "Epoch 00032: loss improved from 1.69703 to 1.66498, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.6650\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6391\n",
      "Epoch 00033: loss improved from 1.66498 to 1.63907, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 1.6391\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6153\n",
      "Epoch 00034: loss improved from 1.63907 to 1.61526, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.6153\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5829\n",
      "Epoch 00035: loss improved from 1.61526 to 1.58286, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.5829\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5507\n",
      "Epoch 00036: loss improved from 1.58286 to 1.55072, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.5507\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5386\n",
      "Epoch 00037: loss improved from 1.55072 to 1.53856, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.5386\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4891\n",
      "Epoch 00038: loss improved from 1.53856 to 1.48911, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.4891\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4877\n",
      "Epoch 00039: loss improved from 1.48911 to 1.48771, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.4877\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4438\n",
      "Epoch 00040: loss improved from 1.48771 to 1.44378, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.4438\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4164\n",
      "Epoch 00041: loss improved from 1.44378 to 1.41643, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.4164\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3911\n",
      "Epoch 00042: loss improved from 1.41643 to 1.39107, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.3911\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3622\n",
      "Epoch 00043: loss improved from 1.39107 to 1.36219, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.3622\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3413\n",
      "Epoch 00044: loss improved from 1.36219 to 1.34133, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 1.3413\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3056\n",
      "Epoch 00045: loss improved from 1.34133 to 1.30563, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.3056\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2959\n",
      "Epoch 00046: loss improved from 1.30563 to 1.29585, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 106s 2s/step - loss: 1.2959\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2570\n",
      "Epoch 00047: loss improved from 1.29585 to 1.25700, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.2570\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2359\n",
      "Epoch 00048: loss improved from 1.25700 to 1.23591, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.2359\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2187\n",
      "Epoch 00049: loss improved from 1.23591 to 1.21874, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.2187\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2085\n",
      "Epoch 00050: loss improved from 1.21874 to 1.20845, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.2085\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1722\n",
      "Epoch 00051: loss improved from 1.20845 to 1.17224, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.1722\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1378\n",
      "Epoch 00052: loss improved from 1.17224 to 1.13779, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.1378\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1133\n",
      "Epoch 00053: loss improved from 1.13779 to 1.11329, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 103s 2s/step - loss: 1.1133\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0896\n",
      "Epoch 00054: loss improved from 1.11329 to 1.08960, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.0896\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0790\n",
      "Epoch 00055: loss improved from 1.08960 to 1.07899, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 1.0790\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0738\n",
      "Epoch 00056: loss improved from 1.07899 to 1.07377, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.0738\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0261\n",
      "Epoch 00057: loss improved from 1.07377 to 1.02611, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.0261\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0148\n",
      "Epoch 00058: loss improved from 1.02611 to 1.01479, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 1.0148\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9955\n",
      "Epoch 00059: loss improved from 1.01479 to 0.99553, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.9955\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9718\n",
      "Epoch 00060: loss improved from 0.99553 to 0.97178, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.9718\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9441\n",
      "Epoch 00061: loss improved from 0.97178 to 0.94405, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.9441\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9382\n",
      "Epoch 00062: loss improved from 0.94405 to 0.93820, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.9382\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9025\n",
      "Epoch 00063: loss improved from 0.93820 to 0.90246, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 106s 2s/step - loss: 0.9025\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9001\n",
      "Epoch 00064: loss improved from 0.90246 to 0.90009, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.9001\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8555\n",
      "Epoch 00065: loss improved from 0.90009 to 0.85554, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.8555\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8598\n",
      "Epoch 00066: loss did not improve from 0.85554\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.8598\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8388\n",
      "Epoch 00067: loss improved from 0.85554 to 0.83875, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.8388\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8289\n",
      "Epoch 00068: loss improved from 0.83875 to 0.82889, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.8289\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8058\n",
      "Epoch 00069: loss improved from 0.82889 to 0.80582, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.8058\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7835\n",
      "Epoch 00070: loss improved from 0.80582 to 0.78347, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7835\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7653\n",
      "Epoch 00071: loss improved from 0.78347 to 0.76529, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7653\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7681\n",
      "Epoch 00072: loss did not improve from 0.76529\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7681\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7459\n",
      "Epoch 00073: loss improved from 0.76529 to 0.74594, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7459\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7238\n",
      "Epoch 00074: loss improved from 0.74594 to 0.72380, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7238\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7177\n",
      "Epoch 00075: loss improved from 0.72380 to 0.71771, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7177\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7171\n",
      "Epoch 00076: loss improved from 0.71771 to 0.71706, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.7171\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6888\n",
      "Epoch 00077: loss improved from 0.71706 to 0.68879, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.6888\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6680\n",
      "Epoch 00078: loss improved from 0.68879 to 0.66801, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.6680\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6685\n",
      "Epoch 00079: loss did not improve from 0.66801\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.6685\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6564\n",
      "Epoch 00080: loss improved from 0.66801 to 0.65640, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 106s 2s/step - loss: 0.6564\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6348\n",
      "Epoch 00081: loss improved from 0.65640 to 0.63477, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.6348\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6278\n",
      "Epoch 00082: loss improved from 0.63477 to 0.62784, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.6278\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6149\n",
      "Epoch 00083: loss improved from 0.62784 to 0.61490, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.6149\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5998\n",
      "Epoch 00084: loss improved from 0.61490 to 0.59976, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5998\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5940\n",
      "Epoch 00085: loss improved from 0.59976 to 0.59396, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5940\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5711\n",
      "Epoch 00086: loss improved from 0.59396 to 0.57106, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5711\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5523\n",
      "Epoch 00087: loss improved from 0.57106 to 0.55233, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5523\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5532\n",
      "Epoch 00088: loss did not improve from 0.55233\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5532\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5713\n",
      "Epoch 00089: loss did not improve from 0.55233\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5713\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5393\n",
      "Epoch 00090: loss improved from 0.55233 to 0.53928, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 105s 2s/step - loss: 0.5393\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5314\n",
      "Epoch 00091: loss improved from 0.53928 to 0.53144, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5314\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5068\n",
      "Epoch 00092: loss improved from 0.53144 to 0.50682, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.5068\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4985\n",
      "Epoch 00093: loss improved from 0.50682 to 0.49853, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4985\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4872\n",
      "Epoch 00094: loss improved from 0.49853 to 0.48717, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4872\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4860\n",
      "Epoch 00095: loss improved from 0.48717 to 0.48601, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4860\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4913\n",
      "Epoch 00096: loss did not improve from 0.48601\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4913\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4631\n",
      "Epoch 00097: loss improved from 0.48601 to 0.46311, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 106s 2s/step - loss: 0.4631\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4685\n",
      "Epoch 00098: loss did not improve from 0.46311\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4685\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4557\n",
      "Epoch 00099: loss improved from 0.46311 to 0.45572, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4557\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4411\n",
      "Epoch 00100: loss improved from 0.45572 to 0.44106, saving model to model_weights_saved.hdf5\n",
      "63/63 [==============================] - 104s 2s/step - loss: 0.4411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2250376a7c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model and letting it train\n",
    "model.fit(X, y, epochs = 100, batch_size = 128, callbacks = desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompiling the model with the saved weights\n",
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to convert the outpit in numbers back to characters\n",
    "num_to_char = dict((i, c) for i, c in enumerate(chars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: \n",
      "\" became torrent course swept away hopes joys natural philosophy genius regulated fate desire therefor \"\n"
     ]
    }
   ],
   "source": [
    "# Providing a random seed to generate text\n",
    "start = numpy.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed: \")\n",
    "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e narration state facts led predilection science bourent inagination childish reasoning till accident changed current ideas fifteen years old retired house near belrive uitnessed hoeatest disdain would science could never even step pifet become sullen study rough ardour nature subdessors mat celight arpeared treasures known besides described always imbued fervent pong mather acqiss mine subpime shapes mountains changes seasons tempest mat celiue shee mather saken pains explain principles agrippa entirely exploded modern system science introduced possessed much crer lapter sone meatent appeared treasures known besides described always imbued fervent pong mather acqiss mine subpime shapes mountains changes seasons tempest mat celiue shee mather saken pains explain principles agrippa entirely exploded modern system science introduced possessed much crer lapter sone meatent appeared treasures known besides described always imbued fervent pong mather acqiss mine subpime shapes mountains cha"
     ]
    }
   ],
   "source": [
    "# Generating the text\n",
    "for i in range (1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/float(vocab_len)\n",
    "    prediction = model.predict(x, verbose = 0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
